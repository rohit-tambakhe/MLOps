# PyTorch Lightning callbacks configuration

model_checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: ${checkpoint_dir}
  filename: "epoch_{epoch:02d}-val_acc_{val/acc:.3f}"
  monitor: ${monitor_metric}
  mode: ${monitor_mode}
  save_top_k: 3
  save_last: true
  auto_insert_metric_name: false

early_stopping:
  _target_: pytorch_lightning.callbacks.EarlyStopping
  monitor: ${monitor_metric}
  mode: ${monitor_mode}
  patience: ${early_stopping_patience}
  verbose: true

lr_monitor:
  _target_: pytorch_lightning.callbacks.LearningRateMonitor
  logging_interval: "epoch"

rich_progress_bar:
  _target_: pytorch_lightning.callbacks.RichProgressBar
